{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ebbfbbc2-bf96-4b6e-972e-3bc935662459",
   "metadata": {},
   "source": [
    "# OS Parser: API example\n",
    "\n",
    "This notebook gives a quick demo of the process of parsing an individual syllabus with the Open Syllabus parser API, and then working with the JSON metedata returned by the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "ad33087f-06df-4516-a9b3-e9a36c4b3cf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import requests\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91a427ab-6a8d-4548-b2e5-b45958010d01",
   "metadata": {},
   "source": [
    "First, we'll add a helper that takes a document as a raw byte string, sends the API request to the model, and then parses the JSON that comes back into a Python dictionary.\n",
    "\n",
    "In this example, we'll directly invoke a [SageMaker](https://aws.amazon.com/sagemaker/) endpoint that's serving the parser model. In production, depending on how access is granted to the model, this might instead involve sending a normal HTTP post request to a URL like `https://parser.opensyllabus.org/api/v1`, using a library like `requests`. But, the output of the model will be exactly the same in either case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "21bc6221-9aaf-417e-b1c9-0140bdcc17a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_syllabus(data: bytes):\n",
    "    \"\"\"Given the raw bytes for a document (HTML, PDF, DOCX, etc), invoke the OS\n",
    "    parser SageMaker endpoint and parse the JSON response.\n",
    "    \"\"\"\n",
    "    client = boto3.client('sagemaker-runtime', region_name='us-east-1')\n",
    "    \n",
    "    # Invoke the parser API.\n",
    "    res = client.invoke_endpoint(EndpointName='os-parser-v1', Body=data)\n",
    "    \n",
    "    # Parse the JSON that comes back from the model.\n",
    "    return json.loads(res['Body'].read())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca5eac02-65f1-4689-af3d-0feccd39102c",
   "metadata": {},
   "source": [
    "## Example: MIT 9.520\n",
    "\n",
    "As an example syllabus, let's use the course webpage for [MIT 9.520, \"Statistical Learning Theory and Applications\"](https://www.mit.edu/~9.520/fall19/). For now, let's just download this directly from the web. (We could also load documents from the local filesystem, query them from a data warehouse, etc.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "d4d4cac1-0be7-4a57-94f7-99a0afbe1fd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "res = requests.get('https://www.mit.edu/~9.520/fall19/')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06d640e3-5ff6-487b-8f52-d2ef9faec055",
   "metadata": {},
   "source": [
    "And then pass the raw HTML data through the parser:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "d0a0bd5f-2feb-474e-8602-2e306f74324b",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = parse_syllabus(res.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4aee1719-8266-4cfe-bf78-64e321c3fb80",
   "metadata": {},
   "source": [
    "This will return a nested Python dictionary that contains all of the metadata extracted from the document in a single bundle. This is organized under a set of top-level keys:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "a1f1a698-2ca8-4fcd-a1d5-9c264afbfa3d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['md5',\n",
       " 'doc_type',\n",
       " 'text',\n",
       " 'syllabus_probability',\n",
       " 'field',\n",
       " 'language',\n",
       " 'institution',\n",
       " 'date',\n",
       " 'urls',\n",
       " 'extracted_sections',\n",
       " 'citations']"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(data.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e99abe6d-d7c9-4f88-b62a-f537e56277ba",
   "metadata": {},
   "source": [
    "### `syllabus_probability`\n",
    "\n",
    "Some of these are very simple, just single values. Eg, `syllabus_probability` is just the probability that the model is a syllabus, as predicted by the top-level document classifier:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "27d26a10-9afb-43d1-a9ea-007b24583489",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9876453612201228"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['syllabus_probability']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f678f2a-7a09-4042-a2e3-90e57a26bf8e",
   "metadata": {},
   "source": [
    "### `institution`\n",
    "\n",
    "Other keys contain more complex metadata. For example, `institution` is a nested object that contains metadata about the college or university where the course was taught. (This is inferred from a combination of signals in the document and the URL it was scraped from.)\n",
    "\n",
    "Under the hood, we link documents against a database of ~22,000 institutions derived from IPEDS, ROR (previously GRID), and Wikidata. By following links to the external identifies, it's possible to get access to a really wide range of standardized metadata about the school. Eg, from Wikidata -\n",
    "\n",
    "https://www.wikidata.org/wiki/Q49108\n",
    "\n",
    "Or GRID:\n",
    "\n",
    "https://grid.ac/institutes/grid.116068.8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e4277a98-221d-4b81-a7b3-129983a282f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'_id': 18108,\n",
       " 'ror_id': '042nb2s44',\n",
       " 'grid_id': 'grid.116068.8',\n",
       " 'wikidata_id': 'Q49108',\n",
       " 'unitid': 166683,\n",
       " 'city': 'Cambridge',\n",
       " 'name': 'Massachusetts Institute of Technology',\n",
       " 'lat': 42.35982,\n",
       " 'lng': -71.09211,\n",
       " 'url': 'http://web.mit.edu/',\n",
       " 'country_code': 'US',\n",
       " 'country': 'United States',\n",
       " 'state_code': 'US-MA',\n",
       " 'state': 'Massachusetts',\n",
       " 'enrollment': 12321,\n",
       " 'two_year': False,\n",
       " 'four_year': True,\n",
       " 'graduate': True,\n",
       " 'research': True}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['institution']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "925f9bd4-f80d-423b-bfa4-81c502e3d7d3",
   "metadata": {},
   "source": [
    "### `date`\n",
    "\n",
    "Or, `date` contains the year and semester in which the course was taught."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d5d9c68d-3951-4017-8c44-e1ae46bba189",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'term': 'fall', 'year': 2019}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['date']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce6cbf05-963a-4195-8f32-b867a62d2342",
   "metadata": {},
   "source": [
    "### `field`\n",
    "\n",
    "And, `field` contains the output from the field classifier.\n",
    "\n",
    "(This taxonomy is a rolled-up version of the the Department of Education [CIP codes](https://nces.ed.gov/ipeds/cipcode/browse.aspx?y=55) - the `cip_codes` key in the Open Syllabus data contains the list of CIP codes that were combined to form the Open Syllabus field.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "44b59db3-d879-4720-b1c3-f8472c032196",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'_id': 45, 'cip_codes': ['27'], 'name': 'Mathematics'}"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['field']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dee0c22d-d07e-43fe-aa8e-9ff7a8c8ec5e",
   "metadata": {},
   "source": [
    "### `extracted_sections`\n",
    "\n",
    "In many ways the core of the output from the parser is `extracted_sections` - this is the output from the top-level document segmentation model that takes the raw document and splits it into a set of 21 standardized entity types:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "922dfc6b-7986-4370-a089-a86e3317982e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['title',\n",
       " 'code',\n",
       " 'section',\n",
       " 'date',\n",
       " 'class_days',\n",
       " 'class_time',\n",
       " 'class_location',\n",
       " 'instructor',\n",
       " 'instructor_phone',\n",
       " 'office_hours_days',\n",
       " 'office_location',\n",
       " 'office_hours_times',\n",
       " 'credits',\n",
       " 'description',\n",
       " 'learning_outcomes',\n",
       " 'citations',\n",
       " 'required_reading',\n",
       " 'grading_rubric',\n",
       " 'assessment_strategy',\n",
       " 'topic_outline',\n",
       " 'assignment_schedule']"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(data['extracted_sections'].keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "2bfa1a74-60ee-46af-b1c1-93570fd27399",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_json(data: dict):\n",
    "    print(json.dumps(data, indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edf65f25-416f-4250-ba65-bd8cf8df7f2f",
   "metadata": {},
   "source": [
    "Under each of these keys is a list of spans of that type that were identified in the document. In many cases, for fields like `title` or `code`, there will be just a single occurrence of the entity in the document. Eg, for `title`, we get `Statistical Learning Theory and Applications`. In addition to the raw text span from the document in the `text` field, the output also includes:\n",
    "\n",
    "- `mean_proba` - The average of the probabilities assigned by the model to the start and end tokens in the span. The closer to 1, the more confident the model was.\n",
    "- `ci1` - The offset of the first character in the span.\n",
    "- `ci2` - The offset of the last character in the span.\n",
    "- `ti1` - The offset of the first token in the tokenizer document.\n",
    "- `ti2` - The offset of the last token in the tokenizer document."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "e860f3cb-c485-4130-a30b-39fc00520a3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\n",
      "  {\n",
      "    \"text\": \"Statistical Learning Theory and Applications\",\n",
      "    \"mean_proba\": 0.96484375,\n",
      "    \"ci1\": 18,\n",
      "    \"ci2\": 61,\n",
      "    \"ti1\": 9,\n",
      "    \"ti2\": 13\n",
      "  }\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "print_json(data['extracted_sections']['title'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ec7af63-4db1-4bd2-bfaf-76eac895ebd5",
   "metadata": {},
   "source": [
    "And, for `code`, we get `9.520/6.860`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "23a863a7-6e98-4de7-9668-455d5efc6cd6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\n",
      "  {\n",
      "    \"text\": \"9.520/6.860\",\n",
      "    \"mean_proba\": 0.8173828125,\n",
      "    \"ci1\": 5,\n",
      "    \"ci2\": 15,\n",
      "    \"ti1\": 0,\n",
      "    \"ti2\": 7\n",
      "  }\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "print_json(data['extracted_sections']['code'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b252874-1813-4f65-82fe-649275ea8799",
   "metadata": {},
   "source": [
    "Other sections can be much longer. Eg, the course description can sometimes be multiple paragraphs, as it is in this case:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "beae4ca3-29ec-4d3d-8a7d-3d2945322bb5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"text\": \"The course covers foundations and recent advances of machine learning from the point of view of statistical learning and regularization theory.\\n      \\nUnderstanding intelligence and how to replicate it in machines is\\narguably one of the greatest problems in science. Learning, its\\nprinciples and computational implementations, is at the very core of\\nintelligence. During the last decade, for the first time, we have been\\nable to develop artificial intelligence systems that begin to solve\\ncomplex tasks, until recently the exclusive domain of biological\\norganisms, such as computer vision, speech recognition or natural\\nlanguage understanding: cameras recognize faces, smart phones\\nunderstand voice commands, smart speakers/assistants answer questions\\nand cars can see and avoid obstacles. The machine learning algorithms\\nthat are at the roots of these success stories are trained with\\nexamples rather than programmed to solve a task.     \\n\\nThe content is roughly divided into three parts. In the first part,\\nkey algorithmic ideas are introduced, with an emphasis on the\\ninterplay between modeling and optimization aspects. Algorithms that\\nwill be discussed include classical regularization (regularized least\\nsquares, SVM, logistic regression, square and exponential loss),\\nstochastic gradient methods, implicit regularization and minimum norm\\nsolutions.    \\nIn the second part, key ideas in statistical learning theory will be\\ndeveloped to analyze the properties of the algorithms previously\\nintroduced. Classical concepts like generalization, uniform\\nconvergence and Rademacher complexities will be developed, together\\nwith topics such as surrogate loss functions for classification,\\nbounds based on margin, stability, and privacy.  \\n\\nThe third part of the course focuses on deep learning networks. It\\nwill introduce theoretical frameworks addressing three key puzzles in\\ndeep learning: approximation theory -- which functions can be\\nrepresented more efficiently by deep networks than shallow networks\\n-- optimization theory -- why can stochastic gradient descent easily\\nfind global minima -- and machine learning -- how generalization in\\ndeep networks used for classification can be explained in terms of\\ncomplexity control implicit in gradient descent. It will also discuss\\nconnections with the architecture of the brain, which was the original\\ninspiration of the layered local connectivity of modern networks and\\nmay provide ideas for future developments and revolutions in networks\\nfor learning.   \\n\\nThe goal of the course is to provide students with the theoretical\\nknowledge and the basic intuitions needed to use and develop effective\\nmachine learning solutions to challenging problems.\",\n",
      "  \"mean_proba\": 0.7880859375,\n",
      "  \"ci1\": 1636,\n",
      "  \"ci2\": 4331,\n",
      "  \"ti1\": 242,\n",
      "  \"ti2\": 696\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "print_json(data['extracted_sections']['description'][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "912caf1d-7023-4eab-bc36-8f7ad7c4e98a",
   "metadata": {},
   "source": [
    "And, some section types will often include multiple matching spans. Eg, here we get 17 `citation` spans:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "36ba1f95-4edf-4322-9692-957f8d18cf4c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data['extracted_sections']['citations'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "b060f784-8293-48ce-8773-676ea42e73bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\n",
      "  {\n",
      "    \"text\": \"L. Rosasco and T. Poggio,  Machine Learning: a Regularization Approach, MIT-9.520 Lectures Notes , Manuscript, Dec. 2017\",\n",
      "    \"mean_proba\": 0.87548828125,\n",
      "    \"ci1\": 6850,\n",
      "    \"ci2\": 6969,\n",
      "    \"ti1\": 1151,\n",
      "    \"ti2\": 1181\n",
      "  },\n",
      "  {\n",
      "    \"text\": \"S. Shalev-Shwartz and S. Ben-David.  Understanding Machine Learning: From Theory to Algorithms.  Cambridge University Press, 2014.\",\n",
      "    \"mean_proba\": 0.9599609375,\n",
      "    \"ci1\": 7031,\n",
      "    \"ci2\": 7160,\n",
      "    \"ti1\": 1188,\n",
      "    \"ti2\": 1217\n",
      "  },\n",
      "  {\n",
      "    \"text\": \"T. Hastie, R. Tibshirani and J. Friedman.  The Elements of Statistical Learning . 2nd Ed., Springer, 2009.\",\n",
      "    \"mean_proba\": 0.9580078125,\n",
      "    \"ci1\": 7169,\n",
      "    \"ci2\": 7274,\n",
      "    \"ti1\": 1218,\n",
      "    \"ti2\": 1247\n",
      "  },\n",
      "  {\n",
      "    \"text\": \"I. Steinwart and A. Christmann.  Support Vector Machines.  Springer, 2008.\",\n",
      "    \"mean_proba\": 0.9619140625,\n",
      "    \"ci1\": 7282,\n",
      "    \"ci2\": 7355,\n",
      "    \"ti1\": 1248,\n",
      "    \"ti2\": 1265\n",
      "  },\n",
      "  {\n",
      "    \"text\": \"O. Bousquet, S. Boucheron and G. Lugosi.  Introduction to Statistical Learning Theory . Advanced Lectures on Machine Learning, LNCS 3176, pp. 169-207. (Eds.) Bousquet, O., U. von Luxburg and G. Ratsch, Springer, 2004.\",\n",
      "    \"mean_proba\": 0.96533203125,\n",
      "    \"ci1\": 7363,\n",
      "    \"ci2\": 7579,\n",
      "    \"ti1\": 1266,\n",
      "    \"ti2\": 1333\n",
      "  },\n",
      "  {\n",
      "    \"text\": \"N. Cristianini and J. Shawe-Taylor.  An Introduction to Support Vector Machines and Other Kernel-based Learning Methods.  Cambridge University Press, 2000.\",\n",
      "    \"mean_proba\": 0.9814453125,\n",
      "    \"ci1\": 7593,\n",
      "    \"ci2\": 7747,\n",
      "    \"ti1\": 1334,\n",
      "    \"ti2\": 1367\n",
      "  },\n",
      "  {\n",
      "    \"text\": \"F. Cucker and S. Smale.  On The Mathematical Foundations of Learning . Bulletin of the American\\n      Mathematical Society, 2002.\",\n",
      "    \"mean_proba\": 0.9833984375,\n",
      "    \"ci1\": 7756,\n",
      "    \"ci2\": 7884,\n",
      "    \"ti1\": 1368,\n",
      "    \"ti2\": 1393\n",
      "  },\n",
      "  {\n",
      "    \"text\": \"F. Cucker and D-X. Zhou.  Learning theory: an approximation theory viewpoint.   Cambridge Monographs on Applied and Computational\\n      Mathematics. Cambridge University Press, 2007.\",\n",
      "    \"mean_proba\": 0.9833984375,\n",
      "    \"ci1\": 7894,\n",
      "    \"ci2\": 8075,\n",
      "    \"ti1\": 1394,\n",
      "    \"ti2\": 1427\n",
      "  },\n",
      "  {\n",
      "    \"text\": \"L. Devroye, L. Gyorfi, and G. Lugosi.  A Probabilistic Theory of Pattern Recognition.  Springer, 1997.\",\n",
      "    \"mean_proba\": 0.9814453125,\n",
      "    \"ci1\": 8084,\n",
      "    \"ci2\": 8185,\n",
      "    \"ti1\": 1428,\n",
      "    \"ti2\": 1461\n",
      "  },\n",
      "  {\n",
      "    \"text\": \"T. Evgeniou, M. Pontil and T. Poggio.  Regularization Networks and Support Vector Machines.  Advances in Computational Mathematics, 2000.\",\n",
      "    \"mean_proba\": 0.98193359375,\n",
      "    \"ci1\": 8194,\n",
      "    \"ci2\": 8330,\n",
      "    \"ti1\": 1462,\n",
      "    \"ti2\": 1493\n",
      "  },\n",
      "  {\n",
      "    \"text\": \"T. Poggio and S. Smale.  The\\n      Mathematics of Learning: Dealing with Data.  Notices of the AMS, 2003.\",\n",
      "    \"mean_proba\": 0.98046875,\n",
      "    \"ci1\": 8339,\n",
      "    \"ci2\": 8443,\n",
      "    \"ti1\": 1494,\n",
      "    \"ti2\": 1520\n",
      "  },\n",
      "  {\n",
      "    \"text\": \"V. N. Vapnik.  Statistical Learning Theory.  Wiley, 1998.\",\n",
      "    \"mean_proba\": 0.9814453125,\n",
      "    \"ci1\": 8452,\n",
      "    \"ci2\": 8508,\n",
      "    \"ti1\": 1521,\n",
      "    \"ti2\": 1536\n",
      "  },\n",
      "  {\n",
      "    \"text\": \"V. N. Vapnik.  The Nature of Statistical Learning Theory.  Springer, 2000.\",\n",
      "    \"mean_proba\": 0.982421875,\n",
      "    \"ci1\": 8517,\n",
      "    \"ci2\": 8590,\n",
      "    \"ti1\": 1537,\n",
      "    \"ti2\": 1555\n",
      "  },\n",
      "  {\n",
      "    \"text\": \"S. Villa, L. Rosasco, T. Poggio.  On Learnability, Complexity and Stability . Empirical Inference: Festschrift in Honor of Vladimir N. Vapnik, Chapter 7, pp. 59-70, Springer-Verlag, 2013.\",\n",
      "    \"mean_proba\": 0.97900390625,\n",
      "    \"ci1\": 8599,\n",
      "    \"ci2\": 8785,\n",
      "    \"ti1\": 1556,\n",
      "    \"ti2\": 1608\n",
      "  },\n",
      "  {\n",
      "    \"text\": \"T. Poggio and F. Anselmi.  Visual Cortex and Deep Networks: Learning Invariant Representations , Computational Neuroscience Series, MIT Press, 2016.\",\n",
      "    \"mean_proba\": 0.970703125,\n",
      "    \"ci1\": 8793,\n",
      "    \"ci2\": 8940,\n",
      "    \"ti1\": 1609,\n",
      "    \"ti2\": 1638\n",
      "  },\n",
      "  {\n",
      "    \"text\": \"T. Poggio, H. Mhaskar, L. Rosasco, B. Miranda, and Q. Liao.  Why and When can Deep-but not Shallow-Networks Avoid the Curse of Dimensionality: A Review . International Journal of Automation and Computing, 1-17, 2017.\",\n",
      "    \"mean_proba\": 0.974609375,\n",
      "    \"ci1\": 8948,\n",
      "    \"ci2\": 9163,\n",
      "    \"ti1\": 1639,\n",
      "    \"ti2\": 1698\n",
      "  },\n",
      "  {\n",
      "    \"text\": \"T. Poggio and Q. Liao.  Theory II: Landscape of the Empirical Risk in Deep Learning . CBMM Memo 66, 2017.\",\n",
      "    \"mean_proba\": 0.9423828125,\n",
      "    \"ci1\": 9171,\n",
      "    \"ci2\": 9275,\n",
      "    \"ti1\": 1699,\n",
      "    \"ti2\": 1727\n",
      "  }\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "print_json(data['extracted_sections']['citations'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f310bf9c-4db7-4cd3-ba0c-0738834dd3ed",
   "metadata": {},
   "source": [
    "## Parsed citations\n",
    "\n",
    "The raw spans extracted from the document can be sufficient for simple fields like `title` or `code` (or for free-text fields like `description`, as input to general text-analysis models). But, in some cases, the raw document sections contain additional sub-structure that can be usefully parsed into structured data.\n",
    "\n",
    "We currently do this for the `citation` strings, which need to be further parsed to extract titles, authors, publishers, editors, and ISBNs, so that we can link them against authoritative records in bibliographic databases. For example, here's the raw text string for one of the extracted citations, as it appeared in the original document:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "29331b9c-1208-42af-bfa4-c63be9ab850a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'S. Shalev-Shwartz and S. Ben-David.  Understanding Machine Learning: From Theory to Algorithms.  Cambridge University Press, 2014.'"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['citations'][1]['doc_span']['text']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c0eb4a1-fbfb-48cf-b464-d5ca0cf35681",
   "metadata": {},
   "source": [
    "And, here's the parsed metadata from the citation parser, which splits the into component parts:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "0170a46c-9366-4571-a4d7-308e4be38e63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"title\": [\n",
      "    {\n",
      "      \"text\": \"Understanding Machine Learning\",\n",
      "      \"mean_proba\": 0.998046875,\n",
      "      \"ci1\": 37,\n",
      "      \"ci2\": 66,\n",
      "      \"ti1\": 15,\n",
      "      \"ti2\": 17\n",
      "    }\n",
      "  ],\n",
      "  \"subtitle\": [\n",
      "    {\n",
      "      \"text\": \"From Theory to Algorithms\",\n",
      "      \"mean_proba\": 0.99267578125,\n",
      "      \"ci1\": 69,\n",
      "      \"ci2\": 93,\n",
      "      \"ti1\": 19,\n",
      "      \"ti2\": 22\n",
      "    }\n",
      "  ],\n",
      "  \"author\": [\n",
      "    {\n",
      "      \"text\": \"S. Shalev-Shwartz\",\n",
      "      \"mean_proba\": 0.998046875,\n",
      "      \"ci1\": 0,\n",
      "      \"ci2\": 16,\n",
      "      \"ti1\": 0,\n",
      "      \"ti2\": 7\n",
      "    },\n",
      "    {\n",
      "      \"text\": \"S. Ben-David\",\n",
      "      \"mean_proba\": 0.998046875,\n",
      "      \"ci1\": 22,\n",
      "      \"ci2\": 33,\n",
      "      \"ti1\": 9,\n",
      "      \"ti2\": 13\n",
      "    }\n",
      "  ],\n",
      "  \"editor\": [],\n",
      "  \"publisher\": [\n",
      "    {\n",
      "      \"text\": \"Cambridge University Press\",\n",
      "      \"mean_proba\": 0.994140625,\n",
      "      \"ci1\": 97,\n",
      "      \"ci2\": 122,\n",
      "      \"ti1\": 24,\n",
      "      \"ti2\": 26\n",
      "    }\n",
      "  ],\n",
      "  \"isbn\": []\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "print_json(data['citations'][1]['parsed_citation'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ed5f020-913a-4896-ac96-eee66adbcafb",
   "metadata": {},
   "source": [
    "And finally, the canonical bibliographic record that was linked to the citation, which contains standardized metadata (good for display in public-facing products), a richer set of third-party identifiers, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "586efa66-4c27-4829-9d20-4d2580379295",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"_id\": 360789702129,\n",
      "  \"work_cluster_size\": 2,\n",
      "  \"sources\": {\n",
      "    \"crossref\": [\n",
      "      \"10.1017/cbo9781107298019\"\n",
      "    ],\n",
      "    \"loc\": [\n",
      "      \"2014001779\"\n",
      "    ]\n",
      "  },\n",
      "  \"title\": \"Understanding Machine Learning\",\n",
      "  \"subtitle\": \"From Foundations to Algorithms\",\n",
      "  \"authors\": [\n",
      "    {\n",
      "      \"forenames\": \"Shai\",\n",
      "      \"keyname\": \"Shalev-Shwartz\"\n",
      "    },\n",
      "    {\n",
      "      \"forenames\": \"Shai\",\n",
      "      \"keyname\": \"Ben-David\"\n",
      "    }\n",
      "  ],\n",
      "  \"publisher\": \"Cambridge University Press\",\n",
      "  \"year\": 2009,\n",
      "  \"dois\": [\n",
      "    \"10.1017/cbo9781107298019\"\n",
      "  ],\n",
      "  \"isbns\": [\n",
      "    \"9781107057135\",\n",
      "    \"1107057132\",\n",
      "    \"9781107298019\"\n",
      "  ],\n",
      "  \"issns\": null,\n",
      "  \"urls\": [\n",
      "    \"http://dx.doi.org/10.1017/cbo9781107298019\"\n",
      "  ],\n",
      "  \"publication_type\": \"book\",\n",
      "  \"open_access\": null,\n",
      "  \"article\": {\n",
      "    \"venue\": null,\n",
      "    \"volume\": null,\n",
      "    \"issue\": null,\n",
      "    \"page_start\": null,\n",
      "    \"page_end\": null,\n",
      "    \"abstract\": null\n",
      "  }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "print_json(data['citations'][1]['catalog_record'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db122701-dac9-4861-9a44-7536ac6b6ed6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
